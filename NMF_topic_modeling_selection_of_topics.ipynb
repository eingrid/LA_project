{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "#change dataset path\n",
    "df = pd.read_csv('data/processed/en_tweets_processed.csv')\n",
    "df = df[df.language == 'en']\n",
    "df = df[~df['text'].isna()]\n",
    "preprocessed_documents = df['text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import matutils\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.9, min_df=4,stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(preprocessed_documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def preprocess_document(doc, tfidf_feature_names_set):\n",
    "    # Lower and split the document only once, and filter using the set\n",
    "    return [word for word in doc.lower().split() if word in tfidf_feature_names_set]\n",
    "\n",
    "\n",
    "def train_NMF(n_components):\n",
    "    model = NMF(n_components=n_components, init='random', random_state=0)\n",
    "    W = model.fit_transform(tfidf)\n",
    "    H = model.components_\n",
    "\n",
    "    # Extract the top words for each topic\n",
    "    n_top_words = 10\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_features = [tfidf_feature_names[i] for i in top_features_ind]\n",
    "        topics.append(top_features)\n",
    "\n",
    "\n",
    "    # Convert tfidf_feature_names to a set for faster lookup\n",
    "    tfidf_feature_names_set = set(tfidf_feature_names)\n",
    "\n",
    "    # Use parallel processing to optimize the conversion of documents into lists of words\n",
    "    with Pool() as pool:\n",
    "        texts = pool.starmap(preprocess_document, [(doc, tfidf_feature_names_set) for doc in preprocessed_documents])\n",
    "\n",
    "    # Create a Gensim dictionary\n",
    "    dictionary = Dictionary(texts)\n",
    "\n",
    "    # Convert the dictionary and the corpus\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # Calculate the coherence score using Gensim\n",
    "    coherence_model = CoherenceModel(topics=topics, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "    print('Coherence Score: ', coherence_score, n_components)\n",
    "    return coherence_score,topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.5817666666622392 5\n",
      "Coherence Score:  0.5731984235089588 10\n",
      "Coherence Score:  0.5155584780161389 15\n",
      "Coherence Score:  0.501634068800048 20\n",
      "Coherence Score:  0.48121169629433086 25\n",
      "Coherence Score:  0.4499379122372345 30\n",
      "Coherence Score:  0.4355715944951517 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/eingrid/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/UCU/LA_PROJECT/env/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py:1770: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.44321204462994324 40\n",
      "Coherence Score:  0.4457580068424277 45\n",
      "Coherence Score:  0.442477204365008 50\n"
     ]
    }
   ],
   "source": [
    "n_components = [5,10,15,20,25,30,35,40,45,50]\n",
    "\n",
    "coherences = []\n",
    "all_topics = []\n",
    "for _n_components in n_components:\n",
    "    coherence_score, topics = train_NMF(_n_components)\n",
    "    coherences.append(coherence_score)\n",
    "    all_topics.append(topics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nuclear',\n",
       "  'plant',\n",
       "  'power',\n",
       "  'zaporizhzhia',\n",
       "  'russia',\n",
       "  'disaster',\n",
       "  'europe',\n",
       "  'largest',\n",
       "  'grid',\n",
       "  'warns'],\n",
       " ['hire',\n",
       "  'passive',\n",
       "  'term',\n",
       "  'awesome',\n",
       "  'website',\n",
       "  'create',\n",
       "  'income',\n",
       "  'autopilot',\n",
       "  'developer',\n",
       "  'clickbank'],\n",
       " ['war',\n",
       "  'russia',\n",
       "  'putin',\n",
       "  'like',\n",
       "  'people',\n",
       "  'world',\n",
       "  'just',\n",
       "  'don',\n",
       "  'stop',\n",
       "  'day'],\n",
       " ['russian',\n",
       "  'ukrainian',\n",
       "  'military',\n",
       "  'video',\n",
       "  'forces',\n",
       "  'air',\n",
       "  'explosions',\n",
       "  'defense',\n",
       "  'region',\n",
       "  'occupied'],\n",
       " ['ukraine',\n",
       "  'support',\n",
       "  'help',\n",
       "  'glory',\n",
       "  'aid',\n",
       "  'weapons',\n",
       "  'new',\n",
       "  'million',\n",
       "  'russia',\n",
       "  'crimea']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
